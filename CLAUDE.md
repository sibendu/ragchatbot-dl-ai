# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Setup and Running

### Prerequisites
- Python 3.13+
- uv (Python package manager)
- Anthropic API key
- **Windows users**: Must use Git Bash for all commands

### Initial Setup
```bash
# Install dependencies - ALWAYS use uv, never pip
uv sync

# Create .env file in root directory
echo "ANTHROPIC_API_KEY=your_key_here" > .env
```

**IMPORTANT:** This project uses `uv` for dependency management. Do NOT use `pip install` directly. Always use `uv` commands to maintain consistency with the lock file.

### Running the Application
```bash
# Preferred method
./run.sh

# Alternative (manual)
cd backend && uv run uvicorn app:app --reload --port 8000
```

- Web UI: http://localhost:8000
- API docs (Swagger): http://localhost:8000/docs

### Development
- The app auto-reloads on file changes (uvicorn --reload)
- No test suite currently exists
- Dependencies are managed via pyproject.toml and locked in uv.lock
- Always run Python commands via `uv run` (e.g., `uv run uvicorn`, `uv run python script.py`)

## Architecture Overview

### Two-Phase Claude API Interaction

The system uses a two-call pattern for Claude API interactions:

1. **First API call** (ai_generator.py:80): Claude receives the user query with `search_course_content` tool definition. Claude decides whether to invoke the tool or answer directly.

2. **Tool execution** (if requested):
   - ToolManager dispatches to CourseSearchTool (search_tools.py:135)
   - VectorStore performs semantic search on ChromaDB (vector_store.py:61-100)
   - Results formatted and returned

3. **Second API call** (ai_generator.py:134): Claude receives tool results and synthesizes final answer. No tools provided in this call.

This pattern is critical: modifying tool execution flow requires understanding both calls work together.

### ChromaDB Two-Collection Architecture

The vector store uses two separate ChromaDB collections (vector_store.py:51-52):

- **`course_catalog`**: Stores course metadata (title, instructor, lessons). Used for semantic course name matching when user provides partial/fuzzy course names (e.g., "MCP" → "Introduction to MCP").

- **`course_content`**: Stores text chunks with embeddings. Metadata includes course_title, lesson_number, and chunk_index for filtering.

**Why two collections?** Course name resolution happens before content search. The catalog enables fuzzy matching on course names, then the resolved exact title filters content search. See vector_store.py:78-83 for resolution logic.

### Document Format Requirements

Documents must follow this exact structure (document_processor.py:97-104):

```
Course Title: [title]
Course Link: [url]
Course Instructor: [instructor]

Lesson 0: [title]
Lesson Link: [url]
[lesson content...]

Lesson 1: [title]
Lesson Link: [url]
[lesson content...]
```

**Parsing behavior:**
- First 3-4 lines parsed for metadata
- Lesson markers MUST match regex: `^Lesson\s+(\d+):\s*(.+)$`
- Lesson numbers are integers (0, 1, 2...)
- Content after metadata but before first lesson marker is ignored
- If no lessons found, entire content treated as single document

Documents placed in `docs/` folder are automatically loaded on server startup (app.py:88-98).

### Session-Based Conversation Management

SessionManager (session_manager.py) maintains in-memory conversation history:
- Session IDs generated by backend (`session_1`, `session_2`...)
- Frontend stores session_id and includes it in subsequent requests
- History limited to `MAX_HISTORY * 2` messages (default: 4 messages = 2 exchanges)
- History formatted as "User: ... Assistant: ..." and injected into Claude's system prompt

**Important:** Sessions are NOT persisted. Server restart clears all conversation history.

### Tool-Based Search Architecture

The AI uses tool calling rather than always searching:
- Claude autonomously decides when to invoke `search_course_content` tool
- System prompt (ai_generator.py:8-30) restricts to **one search per query maximum**
- Tool supports optional filters: `course_name` (string), `lesson_number` (int)
- Sources tracked in tool execution (search_tools.py:112) and returned to frontend separately from answer

When adding new tools:
1. Implement `Tool` abstract class (search_tools.py:6-17)
2. Register with ToolManager (rag_system.py:24-25)
3. Tool definitions automatically included in Claude API calls

### Configuration

All configurable parameters in config.py:
- `ANTHROPIC_MODEL`: "claude-sonnet-4-20250514"
- `EMBEDDING_MODEL`: "all-MiniLM-L6-v2" (SentenceTransformer)
- `CHUNK_SIZE`: 800 characters
- `CHUNK_OVERLAP`: 100 characters
- `MAX_RESULTS`: 5 (search results per query)
- `MAX_HISTORY`: 2 (conversation exchanges to remember)
- `CHROMA_PATH`: "./chroma_db" (persistent vector DB location)

### Startup Behavior

On server startup (app.py:88-98):
- Looks for `../docs` folder relative to backend/
- Processes all `.pdf`, `.docx`, `.txt` files
- **Deduplication:** Checks existing course titles in vector store, skips duplicates
- Does NOT clear existing data unless explicitly called with `clear_existing=True`

To force reload all documents: manually delete `./chroma_db` folder before starting.

## Key File Relationships

- **app.py** → **rag_system.py**: FastAPI delegates all query logic to RAGSystem
- **rag_system.py** orchestrates: document_processor, vector_store, ai_generator, session_manager, tool_manager
- **ai_generator.py** ↔ **search_tools.py**: AIGenerator passes tool_manager for execution during tool_use
- **search_tools.py** → **vector_store.py**: CourseSearchTool calls VectorStore.search()
- **vector_store.py**: Single entry point (search method) handles course resolution + content filtering

## Common Gotchas

1. **Package management**: ALWAYS use `uv` commands (uv sync, uv run, uv add). Never use pip directly. The project relies on uv.lock for reproducible builds.

2. **Windows paths**: Use forward slashes in paths or Path objects. Git Bash required for shell scripts.

3. **ChromaDB persistence**: Vector DB persists in `./chroma_db`. Changes to documents require either deleting this folder or implementing incremental updates.

4. **Embedding model download**: First run downloads `all-MiniLM-L6-v2` model (~90MB). This happens automatically but requires internet.

5. **API key errors**: If missing or invalid, server starts but all queries fail. Check `.env` file exists in root and contains valid key.

6. **Tool calling limits**: System prompt enforces one search per query. Multiple searches require modifying ai_generator.py:8-30.

7. **Session memory**: Frontend must maintain session_id. New session (or null session_id) starts fresh conversation with no history.

## API Endpoints

- `POST /api/query`: Main query endpoint
  - Request: `{query: string, session_id?: string}`
  - Response: `{answer: string, sources: string[], session_id: string}`

- `GET /api/courses`: Course statistics
  - Response: `{total_courses: int, course_titles: string[]}`

- `GET /`: Serves frontend static files (HTML/CSS/JS from `../frontend`)

## Frontend Architecture

Frontend is vanilla JS (no framework):
- **script.js**: Handles fetch requests, markdown rendering (Marked.js), DOM updates
- **index.html**: Chat interface + sidebar with course stats
- **style.css**: Dark theme with CSS variables

Frontend communicates with backend via relative paths (`/api`), making it proxy-friendly.
